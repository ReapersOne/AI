{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce2e76e-8fd2-4a14-95be-2a7bc05fa009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446bcc5-7b3e-4072-87bd-8ec6df59fe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af1577ba4e64fad989f7484b9e53a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/25.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af1577ba4e64fad989f7484b9e53a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/25.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wreep\\.cache\\huggingface\\hub\\datasets--poloclub--diffusiondb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\wreep\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wreep\\.cache\\huggingface\\hub\\datasets--poloclub--diffusiondb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dc19c4915a45779b075aed64331955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusiondb.py:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dc19c4915a45779b075aed64331955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusiondb.py:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf37d6fb9ba8442ba11c411563768d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part-000002.zip:   0%|          | 0.00/512M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf37d6fb9ba8442ba11c411563768d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part-000002.zip:   0%|          | 0.00/512M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset('poloclub/diffusiondb', 'large_first_1k', trust_remote_code=True)\n",
    "df=pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d078e7-7903-45d3-a0ab-d56275bb4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset('poloclub/diffusiondb', 'large_first_50k', trust_remote_code=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605792fe-7fe2-40f4-b427-12bf2bb21dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 10000\n",
    "df_list = []  # List to store DataFrame batches\n",
    "\n",
    "# Process dataset in batches\n",
    "for i in range(0, len(dataset['train']), batch_size):\n",
    "    batch = dataset['train'].select(range(i, min(i + batch_size, len(dataset['train']))))\n",
    "    df_batch = batch.to_pandas()\n",
    "    df_list.append(df_batch)  # Append batch to list\n",
    "\n",
    "# Concatenate all batches into a final DataFrame\n",
    "prompts = pd.concat(df_list, ignore_index=True)\n",
    "secdeset = pd.read_csv('diffusion_db_unaltered.csv')\n",
    "prompts = pd.concat([prompts, secdeset], ignore_index=True)\n",
    "\n",
    "prompts.info()\n",
    "# Display the first few rows\n",
    "prompts.head()\n",
    "prompts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8b529-3491-4b2e-9d2a-b630230bdbc1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a506e07-be42-421d-945e-4b138f32f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = prompts.loc[0, 'image']['path']  # Extract the image path\n",
    "image = Image.open(image_path)\n",
    "image.show()\n",
    "image_array = np.array(image)\n",
    "print(image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7218e-ec27-4a32-9e4f-a31bd5f79ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rgb = image.convert('RGB')\n",
    "image_array = np.expand_dims(image_rgb, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c02a2-76e2-4936-86a2-e8f2563657b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d7697-c0f3-49d1-a7f1-a44032002f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import getpass\n",
    "if openai.api_key is None:\n",
    "    print(' ValueError(\"API key is missing. Please set the OPENAI_API_KEY environment variable.\")')\n",
    "    openai.api_key = getpass.getpass(\"Enter your API key: \")\n",
    "# Initialize the OpenAI client\n",
    "client = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3c594-7bf5-46a3-b918-656148635dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_word(word):\n",
    "    # Define a system message and user prompt to classify each word\n",
    "    prompt = f\"Classify the word '{word}' into one of the following categories: 'illegal', 'explicit', 'violent', 'innocent'. Provide just the category as the output. Ensure one of these categories is no matter what stated.\"\n",
    "\n",
    "    # Call the OpenAI API with the prompt\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        # Parse the response and extract the classification\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        if 'illegal' in classification:\n",
    "            classification = 'illegal'\n",
    "        elif 'explicit' in classification:\n",
    "            classification = 'explicit'\n",
    "        elif 'violent' in classification:\n",
    "            classification = 'violent'\n",
    "        elif 'innocent' in classification:\n",
    "            classification = 'innocent'\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=30\n",
    "        )\n",
    "        # Map the response to a unique value\n",
    "        category_mapping = {\n",
    "            \"illegal\": 1,\n",
    "            \"explicit\": 2,\n",
    "            \"violent\": 3,\n",
    "            \"innocent\": 0\n",
    "        }\n",
    "        \n",
    "        # Return the mapped value\n",
    "        return category_mapping.get(classification, -1)  # Return -1 for unknown categories\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226c5a-6e31-45cc-ae96-5fb9c364a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def numberify(word):\n",
    "    # Define the user prompt\n",
    "    prompt = f\"HERE IS THE WORD: {word}\"\n",
    "\n",
    "    try:\n",
    "        # First classification: 4-digit number\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"Assign the word a number based on the following criteria.\n",
    "    The number will be 4 digits. The first 4 digits determine how 'bad' the word may be.\n",
    "    - Filler words = 1111\n",
    "    - Non-explicit subjects = 2222\n",
    "    - Non-explicit verbs = 3333\n",
    "    - Explicit words increase progressively (e.g., 5555, 6666, 7777, 8888)\n",
    "    - Use 9999 only for extreme cases.\n",
    "    Respond with just the number!.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Second classification: 2-digit number based on implication\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"Assign the word a number from 00 to 99 based on severity.\n",
    "    - Use a balanced scale with 99 reserved for extreme words.\n",
    "    Respond with just the number!.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        secondary = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Third classification: Letter count in 2-digit format\n",
    "        letter_count = len(re.findall(r'[a-zA-Z]', word))\n",
    "        formatted_count = str(letter_count).zfill(2)  # Ensures 2-digit format\n",
    "\n",
    "        # Combine all values into a single 8-digit number\n",
    "        final_number = f\"{classification}{formatted_count}{secondary}\"\n",
    "\n",
    "        return final_number, word  # Returns the combined number and word\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1, word  # Returns -1 on error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6071a-b7e1-470a-a91b-1bbec24fcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ba4c8-f545-45cb-99bf-7bfb9b5751f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Example DataFrame (replace this with your actual DataFrame)\n",
    "\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "words_set = set()\n",
    "# Loop through the DataFrame and classify words across all rows\n",
    "for idx, row in tqdm(prompts.iterrows(), total=len(prompts), desc=\"Processing prompts\"):\n",
    "    prompt = row['prompt']\n",
    "    for word in re.findall(r'\\b\\w+\\b', prompt):  # Split the prompt into individual words\n",
    "        if word not in words_set:  # Avoid classifying the same word twice\n",
    "            words_set.add(word)\n",
    "            word_classifications[word] = {}\n",
    "            classification_value = classify_word(word)\n",
    "            numeric_value, interpreted_word=numberify(word)\n",
    "            rows.append([word, classification_value, numeric_value, interpreted_word])\n",
    "            print(word, classification_value, numeric_value, interpreted_word)\n",
    "        # Sleep to avoid hitting API rate limits\n",
    "        time.sleep(.1)  # Adjust the sleep time as necessary\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better visualization\n",
    "word_classification_df = pd.DataFrame(rows, columns=[\"Word\", \"Classification\", \"Number\", \"NumericInterpretedWord\"])\n",
    "# Display the final DataFrame with words and their classifications\n",
    "print(word_classification_df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844268ab-fb35-4544-8051-fdc4964bddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "def normalize_text(text):\n",
    "    replacements = {\n",
    "        '3': 'E', '5': 'S', '0': 'O', '1': 'I', '2': 'Z'\n",
    "    }\n",
    "    for key, value in replacements.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "\n",
    "# Maintain word order while ensuring uniqueness\n",
    "ordered_words = OrderedDict()\n",
    "prompts['prompt'] = prompts['prompt'].fillna(\"\").astype(str)\n",
    "\n",
    "# Extract words in order from prompts\n",
    "for prompt in tqdm(prompts['prompt'], desc=\"Extracting unique words\"):\n",
    "    prompt = normalize_text(prompt)\n",
    "    words = re.findall(r'\\b\\w+\\b', prompt)\n",
    "    for word in words:\n",
    "        if word not in ordered_words:  # Preserve only first occurrence\n",
    "            ordered_words[word] = None  \n",
    "\n",
    "# Classify words in preserved order\n",
    "rows = []\n",
    "for word in tqdm(ordered_words.keys(), desc=\"Classifying words\"):\n",
    "    classification_value = classify_word(word)\n",
    "    numeric_value, interpreted_word = numberify(word)\n",
    "    rows.append([word, classification_value, numeric_value, interpreted_word])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"Word\", \"Classification\", \"Number\", \"NumericInterpretedWord\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0e2d8-6321-4c5c-baa5-8448c2081aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rows = []\n",
    "for word in tqdm(ordered_words.keys(), desc=\"Validating words\"):\n",
    "    existing_row = next((row for row in rows if row[0] == word), None)\n",
    "\n",
    "    if existing_row:\n",
    "        classification_value = existing_row[1]  \n",
    "        numeric_value = existing_row[2]     \n",
    "        interpreted_word = existing_row[3]\n",
    "\n",
    "        # Recompute only if Classification or Number is -1\n",
    "        if classification_value == -1:\n",
    "            classification_value = classify_word(word)\n",
    "        if numeric_value == -1:\n",
    "            numeric_value, interpreted_word = numberify(word)\n",
    "\n",
    "    else:  # If word is missing from rows, compute everything\n",
    "        classification_value = classify_word(word)\n",
    "        numeric_value, interpreted_word = numberify(word)\n",
    "\n",
    "    valid_rows.append([word, classification_value, numeric_value, interpreted_word])\n",
    "\n",
    "\n",
    "# Update dataframe with validated values\n",
    "df = pd.DataFrame(valid_rows, columns=[\"Word\", \"Classification\", \"Number\", \"NumericInterpretedWord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27628aed-241a-4f2c-b1a7-3baf7970934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Classification'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe2dd0-e935-4ac4-a11d-25d9be516d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns=[\"Word\", \"Classification\", \"Number\", \"NumericInterpretedWord\"])\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecb002-26be-4302-add3-069638c4f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_wordSPECIALIZED(word):\n",
    "    # Define a system message and user prompt to classify each word\n",
    "    prompt = f\"Classify the word '{word}' into one of the following categories: 'illegal', 'explicit', 'violent', 'innocent'. Provide just the category as the output. Ensure one of these categories is no matter what stated.\"\n",
    "\n",
    "    # Call the OpenAI API with the prompt\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        # Parse the response and extract the classification\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        print(classification)\n",
    "        if 'illegal' in classification:\n",
    "            classification = 'illegal'\n",
    "        elif 'explicit' in classification:\n",
    "            classification = 'explicit'\n",
    "        elif 'violent' in classification:\n",
    "            classification = 'violent'\n",
    "        elif 'innocent' in classification:\n",
    "            classification = 'innocent'\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=30\n",
    "        )\n",
    "            classification = response.choices[0].message.content.strip()\n",
    "            print(classification)\n",
    "            if 'illegal' in classification:\n",
    "                classification = 'illegal'\n",
    "            elif 'explicit' in classification:\n",
    "                classification = 'explicit'\n",
    "            elif 'violent' in classification:\n",
    "                classification = 'violent'\n",
    "            elif 'innocent' in classification:\n",
    "                classification = 'innocent'\n",
    "        # Map the response to a unique value\n",
    "        category_mapping = {\n",
    "            \"illegal\": 1,\n",
    "            \"explicit\": 2,\n",
    "            \"violent\": 3,\n",
    "            \"innocent\": 0\n",
    "        }\n",
    "        \n",
    "        # Return the mapped value\n",
    "        return category_mapping.get(classification, -1)  # Return -1 for unknown categories\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013d9c9-e3fb-4eca-a57f-e46f865c62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating words\"):\n",
    "    classification_value = row[\"Classification\"]\n",
    "    numeric_value = row[\"Number\"]\n",
    "\n",
    "    # Recompute only if Classification or Number is -1\n",
    "    if classification_value == -1:\n",
    "        df.at[index, \"Classification\"] = classify_wordSPECIALIZED(row[\"Word\"])\n",
    "    if numeric_value == -1:\n",
    "        df.at[index, \"Number\"], df.at[index, \"NumericInterpretedWord\"] = numberify(row[\"Word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73b51f-bb50-41e4-9f52-de91a502df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Classification'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7323174-1473-4fda-9041-f3460b217373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Classification'] == -1, 'Classification'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c68cd-4acf-4dfd-948f-55ee7df1395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513c389-10fe-4980-8a81-c1328a0f376f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_class_1 = len(df.loc[df['Classification'] == 1])\n",
    "count_class_2 = len(df.loc[df['Classification'] == 2])\n",
    "count_class_3 = len(df.loc[df['Classification'] == 3])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Count of Classification 1: {count_class_1}\")\n",
    "print(f\"Count of Classification 2: {count_class_2}\")\n",
    "print(f\"Count of Classification 3: {count_class_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c6840-c803-414b-8024-f12af10a3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Classification'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854246a-99ac-4417-8ea0-eaeccd6c0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('WordList.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7115f24-7016-4687-b22c-0cb28bd80892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conditions: combination of 2 or more illicit classifications 1+2, 2+3, 1+3\n",
    "Repetition: 3 or more repitions of the same illicit classification\n",
    "average of numbers: if the average number is over 50000000\n",
    "High number: If there is any instance of a number over 60000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd2b3e-52fc-45b3-957c-a3fcf831a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "SafePrompt='Generate an image of a child looking to the starry night'\n",
    "NSFWPrompt='Generate an image of a busty looking female with big boobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b07981-72e4-4cee-9a82-e0ace6d1ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f9464-a26c-42e4-a8bf-c1ee7e87ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts['Banned'] = (prompts['prompt_nsfw'] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8235d-b90d-4b71-a070-abe5727788b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f57007-a5f2-4836-bd69-f9c16003f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts['allowed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f29568-6a35-4ab1-afcd-1e2e0e228401",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0bd34-e96b-4b17-864d-1e7b586f997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "df_dict = df.set_index('Word')[['Classification', 'Number']].to_dict(orient='index')\n",
    "\n",
    "for idx, row in tqdm(prompts.iterrows(), total=len(prompts), desc=\"Processing prompts\"):\n",
    "    Classprompt = row['prompt']\n",
    "    Numprompt = row['prompt']\n",
    "\n",
    "    Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "    Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Numprompt) \n",
    "    for word in re.findall(r'\\b\\w+\\b', Classprompt):  \n",
    "        if word in df_dict:\n",
    "            classification_value = df_dict[word]['Classification']\n",
    "            numeric_value = df_dict[word]['Number']\n",
    "        else:\n",
    "            classification_value = classify_word(word)\n",
    "            numeric_value, _ = numberify(word)\n",
    "        Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(classification_value), Classprompt)\n",
    "        Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(numeric_value), Numprompt)\n",
    "\n",
    "    prompts.at[idx, 'Classprompt'] = str(Classprompt) \n",
    "    prompts.at[idx, 'Numprompt'] = str(Numprompt) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba3b67-5423-4dae-a06d-3dc19157cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head(867760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c6b7c-f890-48e7-bc57-70482f59c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre filtering\n",
    "prompts['Class 3 appearance count'] = prompts['Classprompt'].str.count('3')\n",
    "prompts['Class 2 appearance count'] = prompts['Classprompt'].str.count('2')\n",
    "prompts['Class 1 appearance count'] = prompts['Classprompt'].str.count('1')\n",
    "\n",
    "prompts['Class Sum count'] = (\n",
    "    prompts['Class 3 appearance count'] +\n",
    "    prompts['Class 2 appearance count'] +\n",
    "    prompts['Class 1 appearance count']\n",
    ")\n",
    "\n",
    "prompts.loc[prompts['Class 3 appearance count'] > 4, 'Guess allowed'] = 0\n",
    "prompts.loc[prompts['Class 2 appearance count'] > 4, 'Guess allowed'] = 0\n",
    "prompts.loc[prompts['Class 1 appearance count'] > 4, 'Guess allowed'] = 0\n",
    "prompts.loc[prompts['Class Sum count'] > 4, 'Guess allowed'] = 0\n",
    "\n",
    "prompts['Numbers'] = prompts['Numprompt'].fillna(\"\").astype(str).str.findall(r'\\d+').apply(lambda x: list(map(int, x)) if x else [])\n",
    "\n",
    "prompts['Average Number'] = prompts['Numbers'].apply(lambda x: sum(x)/len(x) if x else 0)\n",
    "prompts.loc[prompts['Average Number'] > 50000000, 'Guess allowed'] = 0\n",
    "prompts.loc[prompts['Average Number'] <= 50000000, 'Guess allowed'] = 1\n",
    "\n",
    "prompts.loc[prompts['Numbers'].apply(lambda x: any(num > 60000000 for num in x)), 'Guess allowed'] = 0\n",
    "\n",
    "\"\"\"\n",
    "Conditions: combination of 2 or more illicit classifications 1+2, 2+3, 1+3\n",
    "Repetition: 3 or more repitions of the same illicit classification\n",
    "average of numbers: if the average number is over 50000000\n",
    "High number: If there is any instance of a number over 60000000\n",
    "\"\"\"\n",
    "prompts.head()\n",
    "#prompts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac37cc-8f0a-4a00-85dd-7312064c7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(prompts.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f0ed2-f70f-4ad9-a859-5def590381d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = prompts.head(867760)\n",
    "if 'Guess allowed' in df_subset.columns and 'allowed' in df_subset.columns:\n",
    "    true_positives = (df_subset['Guess allowed'] == 1) & (df_subset['allowed'] == 1)\n",
    "\n",
    "    true_negatives = (df_subset['Guess allowed'] == 0) & (df_subset['allowed'] == 0)\n",
    "\n",
    "    false_positives = (df_subset['Guess allowed'] == 1) & (df_subset['allowed'] == 0)\n",
    "\n",
    "    false_negatives = (df_subset['Guess allowed'] == 0) & (df_subset['allowed'] == 1)\n",
    "\n",
    "    tp_count = true_positives.sum()\n",
    "    tn_count = true_negatives.sum()\n",
    "    fp_count = false_positives.sum()\n",
    "    fn_count = false_negatives.sum()\n",
    "\n",
    "    print(f\"True Positives (TP): {tp_count}\")\n",
    "    print(f\"True Negatives (TN): {tn_count}\")\n",
    "    print(f\"False Positives (FP): {fp_count}\")\n",
    "    print(f\"False Negatives (FN): {fn_count}\")\n",
    "    total = len(df_subset)\n",
    "\n",
    "    tp_percentage = (tp_count / total) * 100\n",
    "    tn_percentage = (tn_count / total) * 100\n",
    "    fp_percentage = (fp_count / total) * 100\n",
    "    fn_percentage = (fn_count / total) * 100\n",
    "\n",
    "    print(f\"True Positives Ratio: {tp_percentage:.2f}%\")\n",
    "    print(f\"True Negatives Ratio: {tn_percentage:.2f}%\")\n",
    "    print(f\"False Positives Ratio: {fp_percentage:.2f}%\")\n",
    "    print(f\"False Negatives Ratio: {fn_percentage:.2f}%\")\n",
    "\n",
    "    accuracy = (tp_count + tn_count) / len(df_subset)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"The required columns are not present in the first 100 rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80bfd2-fe4b-4883-acbc-162f01806371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your custom prompt here (replace this with your actual prompt)\n",
    "custom_prompt = NSFWPrompt\n",
    "\n",
    "# Initialize the word classifications (use your pre-built logic)\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "\n",
    "# Process the custom prompt\n",
    "Classprompt = custom_prompt\n",
    "Numprompt = custom_prompt\n",
    "\n",
    "# Clean up non-alphabetical characters (remove special characters)\n",
    "Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Numprompt)\n",
    "\n",
    "# Process words and classify them\n",
    "for word in re.findall(r'\\b\\w+\\b', Classprompt):  # Loop through each word\n",
    "    if word not in word_classifications:\n",
    "        classification_value = classify_word(word)  # Classify word (you'll have to define this)\n",
    "        numeric_value, interpreted_word = numberify(word)  # Interpret numeric value (define this too)\n",
    "        word_classifications[word] = {'Classification': classification_value, \n",
    "                                       'Number': numeric_value, 'NumericInterpretedWord': interpreted_word}\n",
    "    else:\n",
    "        classification_value = word_classifications[word]['Classification']\n",
    "        numeric_value = word_classifications[word]['Number']\n",
    "    \n",
    "    # Replace the word in the prompts with the classification and numeric value\n",
    "    Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(classification_value), Classprompt)\n",
    "    Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(numeric_value), Numprompt)\n",
    "\n",
    "# Output the processed prompt with classifications and numeric values\n",
    "print(\"Processed Classprompt:\", Classprompt)\n",
    "print(\"Processed Numprompt:\", Numprompt)\n",
    "\n",
    "# Pre-filtering based on the same logic as before\n",
    "Class_3_count = Classprompt.count('3')\n",
    "Class_2_count = Classprompt.count('2')\n",
    "Class_1_count = Classprompt.count('1')\n",
    "\n",
    "Class_Sum_count = Class_3_count + Class_2_count + Class_1_count\n",
    "\n",
    "# Apply filtering conditions\n",
    "Guess_allowed = 1  # Default assumption (if conditions are not violated)\n",
    "if Class_3_count > 4 or Class_2_count > 4 or Class_1_count > 4 or Class_Sum_count > 4:\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Extract numbers from Numprompt\n",
    "Numbers = list(map(int, re.findall(r'\\d+', Numprompt)))\n",
    "Average_Number = sum(Numbers)/len(Numbers) if Numbers else 0\n",
    "\n",
    "if Average_Number > 50000000:\n",
    "    Guess_allowed = 0\n",
    "elif any(num > 60000000 for num in Numbers):\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Print the result for the custom prompt\n",
    "print(f\"Guess allowed: {Guess_allowed}\")\n",
    "\n",
    "# Assuming you have the actual label `allowed` for your custom prompt (manually define it here)\n",
    "# For this example, let's assume the actual label is stored in `actual_allowed`:\n",
    "actual_allowed = 0  # You would replace this with the actual expected result for your custom prompt\n",
    "\n",
    "# Calculate the accuracy or compare the results\n",
    "if Guess_allowed == actual_allowed:\n",
    "    print(\"Prediction is correct.\")\n",
    "else:\n",
    "    print(\"Prediction is incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a2d6f-0275-43b1-ab67-0b70ca1655af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your custom prompt here (replace this with your actual prompt)\n",
    "custom_prompt = SafePrompt\n",
    "\n",
    "# Initialize the word classifications (use your pre-built logic)\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "\n",
    "# Process the custom prompt\n",
    "Classprompt = custom_prompt\n",
    "Numprompt = custom_prompt\n",
    "\n",
    "# Clean up non-alphabetical characters (remove special characters)\n",
    "Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Numprompt)\n",
    "\n",
    "# Process words and classify them\n",
    "for word in re.findall(r'\\b\\w+\\b', Classprompt):  # Loop through each word\n",
    "    if word not in word_classifications:\n",
    "        classification_value = classify_word(word)  # Classify word (you'll have to define this)\n",
    "        numeric_value, interpreted_word = numberify(word)  # Interpret numeric value (define this too)\n",
    "        word_classifications[word] = {'Classification': classification_value, \n",
    "                                       'Number': numeric_value, 'NumericInterpretedWord': interpreted_word}\n",
    "    else:\n",
    "        classification_value = word_classifications[word]['Classification']\n",
    "        numeric_value = word_classifications[word]['Number']\n",
    "    \n",
    "    # Replace the word in the prompts with the classification and numeric value\n",
    "    Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(classification_value), Classprompt)\n",
    "    Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(numeric_value), Numprompt)\n",
    "\n",
    "# Output the processed prompt with classifications and numeric values\n",
    "print(\"Processed Classprompt:\", Classprompt)\n",
    "print(\"Processed Numprompt:\", Numprompt)\n",
    "\n",
    "# Pre-filtering based on the same logic as before\n",
    "Class_3_count = Classprompt.count('3')\n",
    "Class_2_count = Classprompt.count('2')\n",
    "Class_1_count = Classprompt.count('1')\n",
    "\n",
    "Class_Sum_count = Class_3_count + Class_2_count + Class_1_count\n",
    "\n",
    "# Apply filtering conditions\n",
    "Guess_allowed = 1  # Default assumption (if conditions are not violated)\n",
    "if Class_3_count > 4 or Class_2_count > 4 or Class_1_count > 4 or Class_Sum_count > 4:\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Extract numbers from Numprompt\n",
    "Numbers = list(map(int, re.findall(r'\\d+', Numprompt)))\n",
    "Average_Number = sum(Numbers)/len(Numbers) if Numbers else 0\n",
    "\n",
    "if Average_Number > 50000000:\n",
    "    Guess_allowed = 0\n",
    "elif any(num > 60000000 for num in Numbers):\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Print the result for the custom prompt\n",
    "print(f\"Guess allowed: {Guess_allowed}\")\n",
    "\n",
    "# Assuming you have the actual label `allowed` for your custom prompt (manually define it here)\n",
    "# For this example, let's assume the actual label is stored in `actual_allowed`:\n",
    "actual_allowed = 1  # You would replace this with the actual expected result for your custom prompt\n",
    "\n",
    "# Calculate the accuracy or compare the results\n",
    "if Guess_allowed == actual_allowed:\n",
    "    print(\"Prediction is correct.\")\n",
    "else:\n",
    "    print(\"Prediction is incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d50d99-56c2-4cd7-9cf0-f003092042af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85ff10-5ad3-4358-bba2-22340ce5cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_subset['Numbers'].apply(lambda x: sum(x) if isinstance(x, list) else 0).values.reshape(-1, 1)  # If 'Numbers' is a list, sum them as a feature\n",
    "y = df_subset['allowed']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "tp_values, tn_values, fp_values, fn_values = [], [], [], []\n",
    "\n",
    "# Loop over different values of k and compute the accuracy\n",
    "for k in range(1, 13):  # Test values of k from 1 to 12\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Results for k={k}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 5: Make Predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Step 6: Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy for k={k}: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix for k={k}:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Extract the components of the confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f\"\\nTrue Positives (TP): {tp}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    \n",
    "    # Additional metrics (optional)\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    tp_values.append(tp)\n",
    "    tn_values.append(tn)\n",
    "    fp_values.append(fp)\n",
    "    fn_values.append(fn)\n",
    "    print(f\"Precision for k={k}: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall for k={k}: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score for k={k}: {f1_score * 100:.2f}%\")\n",
    "    \n",
    "    # Print the first 5 predicted values and their actual counterparts\n",
    "    print(\"\\nFirst 5 predictions vs actual values:\")\n",
    "    for i in range(5):\n",
    "        print(f\"Sample {i+1} - Predicted: {y_pred[i]}, Actual: {y_test.iloc[i]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "k_values = list(range(1, 13))\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 3 rows, 2 columns\n",
    "\n",
    "# Define plot data\n",
    "metrics = [\n",
    "    (tp_values, \"True Positives\", \"green\", \"o\"),\n",
    "    (tn_values, \"True Negatives\", \"blue\", \"s\"),\n",
    "    (fp_values, \"False Positives\", \"red\", \"^\"),\n",
    "    (fn_values, \"False Negatives\", \"orange\", \"v\"),\n",
    "    (accuracies, \"Accuracy\", \"purple\", \"D\")\n",
    "]\n",
    "\n",
    "# Plot each metric\n",
    "for i, (values, title, color, marker) in enumerate(metrics):\n",
    "    row, col = divmod(i, 2)  # Calculate subplot position\n",
    "    axes[row, col].plot(k_values, values, marker=marker, linestyle=\"-\", color=color, label=title)\n",
    "    axes[row, col].set_xlabel(\"k (Number of Neighbors)\")\n",
    "    axes[row, col].set_ylabel(\"Count\" if title != \"Accuracy\" else \"Score\")\n",
    "    axes[row, col].set_title(f\"{title} Across Different k Values\")\n",
    "    axes[row, col].grid(True)\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Hide the empty subplot (bottom-right)\n",
    "fig.delaxes(axes[2, 1])\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f315c7-5f4d-4460-8b72-b2b5be81f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the model 'knn' is already trained\n",
    "\n",
    "# Define your custom prompt here (replace this with your actual prompt)\n",
    "custom_prompt = NSFWPrompt\n",
    "\n",
    "# Initialize the word classifications (use your pre-built logic)\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "\n",
    "# Process the custom prompt\n",
    "Classprompt = custom_prompt\n",
    "Numprompt = custom_prompt\n",
    "\n",
    "# Clean up non-alphabetical characters (remove special characters)\n",
    "Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Numprompt)\n",
    "\n",
    "# Process words and classify them\n",
    "for word in re.findall(r'\\b\\w+\\b', Classprompt):  # Loop through each word\n",
    "    if word not in word_classifications:\n",
    "        # Here, classify the word based on your own logic, e.g., classify_word, numberify\n",
    "        classification_value = classify_word(word)  # Classify word (you'll have to define this)\n",
    "        numeric_value, interpreted_word = numberify(word)  # Interpret numeric value (define this too)\n",
    "        word_classifications[word] = {'Classification': classification_value, \n",
    "                                       'Number': numeric_value, 'NumericInterpretedWord': interpreted_word}\n",
    "    else:\n",
    "        classification_value = word_classifications[word]['Classification']\n",
    "        numeric_value = word_classifications[word]['Number']\n",
    "    \n",
    "    # Replace the word in the prompts with the classification and numeric value\n",
    "    Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(classification_value), Classprompt)\n",
    "    Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(numeric_value), Numprompt)\n",
    "\n",
    "# Output the processed prompt with classifications and numeric values\n",
    "print(\"Processed Classprompt:\", Classprompt)\n",
    "print(\"Processed Numprompt:\", Numprompt)\n",
    "\n",
    "# Pre-filtering based on the same logic as before\n",
    "Class_3_count = Classprompt.count('3')\n",
    "Class_2_count = Classprompt.count('2')\n",
    "Class_1_count = Classprompt.count('1')\n",
    "\n",
    "Class_Sum_count = Class_3_count + Class_2_count + Class_1_count\n",
    "\n",
    "# Apply filtering conditions\n",
    "Guess_allowed = 1  # Default assumption (if conditions are not violated)\n",
    "if Class_3_count > 4 or Class_2_count > 4 or Class_1_count > 4 or Class_Sum_count > 4:\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Extract numbers from Numprompt\n",
    "Numbers = list(map(int, re.findall(r'\\d+', Numprompt)))\n",
    "Average_Number = sum(Numbers)/len(Numbers) if Numbers else 0\n",
    "\n",
    "if Average_Number > 50000000:\n",
    "    Guess_allowed = 0\n",
    "elif any(num > 60000000 for num in Numbers):\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Print the result for the custom prompt\n",
    "print(f\"Guess allowed: {Guess_allowed}\")\n",
    "\n",
    "# Assuming you have the actual label `allowed` for your custom prompt (manually define it here)\n",
    "# For this example, let's assume the actual label is stored in `actual_allowed`:\n",
    "actual_allowed = 0  # You would replace this with the actual expected result for your custom prompt\n",
    "\n",
    "# Calculate the accuracy or compare the results\n",
    "if Guess_allowed == actual_allowed:\n",
    "    print(\"Filter is correct.\")\n",
    "else:\n",
    "    print(\"Filter is incorrect.\")\n",
    "\n",
    "# Preprocess the custom prompt (as you did with your training data)\n",
    "def preprocess_custom_prompt(prompt):\n",
    "    # Extract numbers from the prompt\n",
    "    numbers = re.findall(r'\\d+', prompt)\n",
    "    \n",
    "    # Convert the numbers to integers\n",
    "    numbers = list(map(int, numbers))\n",
    "    \n",
    "    # Sum the numbers (or any other feature engineering you want to use)\n",
    "    sum_of_numbers = sum(numbers) if numbers else 0\n",
    "    \n",
    "    # Return the feature as an array (reshape to match the model input)\n",
    "    return np.array([[sum_of_numbers]])\n",
    "\n",
    "# Preprocess the custom prompt for KNN input\n",
    "X_custom = preprocess_custom_prompt(custom_prompt)\n",
    "\n",
    "# Predict the class for the custom prompt using KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "custom_prediction = knn.predict(X_custom)\n",
    "if custom_prediction == actual_allowed:\n",
    "    print(\"KNN Prediction is correct.\")\n",
    "else:\n",
    "    print(\"KNN Prediction is incorrect.\")\n",
    "# Output the KNN prediction result\n",
    "print(f\"KNN Prediction for the custom prompt: {custom_prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc803c05-62ca-45cd-9dff-9475fb18c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the model 'knn' is already trained\n",
    "\n",
    "# Define your custom prompt here (replace this with your actual prompt)\n",
    "custom_prompt = SafePrompt\n",
    "\n",
    "# Initialize the word classifications (use your pre-built logic)\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "\n",
    "# Process the custom prompt\n",
    "Classprompt = custom_prompt\n",
    "Numprompt = custom_prompt\n",
    "\n",
    "# Clean up non-alphabetical characters (remove special characters)\n",
    "Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Numprompt)\n",
    "\n",
    "# Process words and classify them\n",
    "for word in re.findall(r'\\b\\w+\\b', Classprompt):  # Loop through each word\n",
    "    if word not in word_classifications:\n",
    "        # Here, classify the word based on your own logic, e.g., classify_word, numberify\n",
    "        classification_value = classify_word(word)  # Classify word (you'll have to define this)\n",
    "        numeric_value, interpreted_word = numberify(word)  # Interpret numeric value (define this too)\n",
    "        word_classifications[word] = {'Classification': classification_value, \n",
    "                                       'Number': numeric_value, 'NumericInterpretedWord': interpreted_word}\n",
    "    else:\n",
    "        classification_value = word_classifications[word]['Classification']\n",
    "        numeric_value = word_classifications[word]['Number']\n",
    "    \n",
    "    # Replace the word in the prompts with the classification and numeric value\n",
    "    Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(classification_value), Classprompt)\n",
    "    Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(numeric_value), Numprompt)\n",
    "\n",
    "# Output the processed prompt with classifications and numeric values\n",
    "print(\"Processed Classprompt:\", Classprompt)\n",
    "print(\"Processed Numprompt:\", Numprompt)\n",
    "\n",
    "# Pre-filtering based on the same logic as before\n",
    "Class_3_count = Classprompt.count('3')\n",
    "Class_2_count = Classprompt.count('2')\n",
    "Class_1_count = Classprompt.count('1')\n",
    "\n",
    "Class_Sum_count = Class_3_count + Class_2_count + Class_1_count\n",
    "\n",
    "# Apply filtering conditions\n",
    "Guess_allowed = 1  # Default assumption (if conditions are not violated)\n",
    "if Class_3_count > 4 or Class_2_count > 4 or Class_1_count > 4 or Class_Sum_count > 4:\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Extract numbers from Numprompt\n",
    "Numbers = list(map(int, re.findall(r'\\d+', Numprompt)))\n",
    "Average_Number = sum(Numbers)/len(Numbers) if Numbers else 0\n",
    "\n",
    "if Average_Number > 50000000:\n",
    "    Guess_allowed = 0\n",
    "elif any(num > 60000000 for num in Numbers):\n",
    "    Guess_allowed = 0\n",
    "\n",
    "# Print the result for the custom prompt\n",
    "print(f\"Guess allowed: {Guess_allowed}\")\n",
    "\n",
    "# Assuming you have the actual label `allowed` for your custom prompt (manually define it here)\n",
    "# For this example, let's assume the actual label is stored in `actual_allowed`:\n",
    "actual_allowed = 1  # You would replace this with the actual expected result for your custom prompt\n",
    "\n",
    "# Calculate the accuracy or compare the results\n",
    "if Guess_allowed == actual_allowed:\n",
    "    print(\"Filter is correct.\")\n",
    "else:\n",
    "    print(\"Filter is incorrect.\")\n",
    "\n",
    "# Preprocess the custom prompt (as you did with your training data)\n",
    "def preprocess_custom_prompt(prompt):\n",
    "    # Extract numbers from the prompt\n",
    "    numbers = re.findall(r'\\d+', prompt)\n",
    "    \n",
    "    # Convert the numbers to integers\n",
    "    numbers = list(map(int, numbers))\n",
    "    \n",
    "    # Sum the numbers (or any other feature engineering you want to use)\n",
    "    sum_of_numbers = sum(numbers) if numbers else 0\n",
    "    \n",
    "    # Return the feature as an array (reshape to match the model input)\n",
    "    return np.array([[sum_of_numbers]])\n",
    "\n",
    "# Preprocess the custom prompt for KNN input\n",
    "X_custom = preprocess_custom_prompt(custom_prompt)\n",
    "\n",
    "# Predict the class for the custom prompt using KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "custom_prediction = knn.predict(X_custom)\n",
    "if custom_prediction == actual_allowed:\n",
    "    print(\"KNN Prediction is correct.\")\n",
    "else:\n",
    "    print(\"KNN Prediction is incorrect.\")\n",
    "# Output the KNN prediction result\n",
    "print(f\"KNN Prediction for the custom prompt: {custom_prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26136e7-6046-4d8a-b406-91307b2725b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bd93d-621c-456a-9ce0-e045463e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211a55a-ec7c-4ce0-a276-bac3ccd0aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_subset['Numbers'].apply(lambda x: sum(x) if isinstance(x, list) else 0).values.reshape(-1, 1)\n",
    "y = df_subset['allowed']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Initialize Nave Bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Store metrics for graphing\n",
    "accuracies = [accuracy_score(y_test, y_pred)]\n",
    "tp_values = [tp]\n",
    "tn_values = [tn]\n",
    "fp_values = [fp]\n",
    "fn_values = [fn]\n",
    "\n",
    "# Print results\n",
    "print(\"=\"*50)\n",
    "print(\"Results for Nave Bayes Classifier\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "print(f\"\\nTrue Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "# Compute additional metrics\n",
    "precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracies[0] * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score * 100:.2f}%\")\n",
    "\n",
    "# Create bar plot for the confusion matrix components\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics = ['True Positives', 'True Negatives', 'False Positives', 'False Negatives']\n",
    "values = [tp, tn, fp, fn]\n",
    "colors = ['green', 'blue', 'red', 'orange']\n",
    "\n",
    "ax.bar(metrics, values, color=colors)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Confusion Matrix Breakdown for Nave Bayes\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f947e2e-686a-4963-9924-e344bbf5d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_subset['Numbers'].apply(lambda x: sum(x) if isinstance(x, list) else 0).values.reshape(-1, 1)  # If 'Numbers' is a list, sum them as a feature\n",
    "y = df_subset['allowed']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "tp_values, tn_values, fp_values, fn_values = [], [], [], []\n",
    "\n",
    "# Loop over different values of k and compute the accuracy\n",
    "for k in range(1, 13):  # Test values of k from 1 to 12\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Results for k={k}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Step 5: Make Predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Step 6: Evaluate the Model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy for k={k}: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix for k={k}:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Extract the components of the confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f\"\\nTrue Positives (TP): {tp}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    \n",
    "    # Additional metrics (optional)\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    tp_values.append(tp)\n",
    "    tn_values.append(tn)\n",
    "    fp_values.append(fp)\n",
    "    fn_values.append(fn)\n",
    "    print(f\"Precision for k={k}: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall for k={k}: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score for k={k}: {f1_score * 100:.2f}%\")\n",
    "    \n",
    "    # Print the first 5 predicted values and their actual counterparts\n",
    "    print(\"\\nFirst 5 predictions vs actual values:\")\n",
    "    for i in range(5):\n",
    "        print(f\"Sample {i+1} - Predicted: {y_pred[i]}, Actual: {y_test.iloc[i]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "k_values = list(range(1, 13))\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 3 rows, 2 columns\n",
    "\n",
    "# Define plot data\n",
    "metrics = [\n",
    "    (tp_values, \"True Positives\", \"green\", \"o\"),\n",
    "    (tn_values, \"True Negatives\", \"blue\", \"s\"),\n",
    "    (fp_values, \"False Positives\", \"red\", \"^\"),\n",
    "    (fn_values, \"False Negatives\", \"orange\", \"v\"),\n",
    "    (accuracies, \"Accuracy\", \"purple\", \"D\")\n",
    "]\n",
    "\n",
    "# Plot each metric\n",
    "for i, (values, title, color, marker) in enumerate(metrics):\n",
    "    row, col = divmod(i, 2)  # Calculate subplot position\n",
    "    axes[row, col].plot(k_values, values, marker=marker, linestyle=\"-\", color=color, label=title)\n",
    "    axes[row, col].set_xlabel(\"k (Number of Neighbors)\")\n",
    "    axes[row, col].set_ylabel(\"Count\" if title != \"Accuracy\" else \"Score\")\n",
    "    axes[row, col].set_title(f\"{title} Across Different k Values\")\n",
    "    axes[row, col].grid(True)\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Hide the empty subplot (bottom-right)\n",
    "fig.delaxes(axes[2, 1])\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8004f-ff77-4813-8262-8791c796e882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
